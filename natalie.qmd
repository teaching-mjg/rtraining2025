# Natalie

## Natalie Method 1

I have around 100 individual data files for the Cambridge Face Memory Test long form, The Cambridge car test, a 3 back task (RESULTS_FILE) and the models memory test (23255_P01). All the example files for a participant are attached. I want to be able to collate the data across participants and calculate performance â€“ each file type has a different structure, and some already have a performance summary that can be extracted.
 
```{r, echo=F, message=F}
library(tidyverse)
library(knitr)
```
 

```{r}
data_dir = "data_supplied/natalie"
files_list = list.files(data_dir, full.names = T, pattern="*.csv|*.txt")
files_list %>% kable(col.names = NULL)
```

### File 1 Models Memory Task

Read in the file.

```{r, message=F}
print(files_list[1])
file1 = read_csv(files_list[1], show_col_types = FALSE)
```

Show the first few rows.

```{r}
file1 %>% head() %>% kable()
```

Summarise accuracy, per type of Correct Response, by including Correct Response in the arguments of `group_by()`

```{r, echo=T, message=F}
file1 %>% 
  group_by(`Participant Code`, `Correct Response`) %>% 
  summarise(mean_correct = mean(`Response Correct`)) %>% 
  kable(digits=2)
```

Summarise accuracy to get a mean for each participant collapsing over type of Correct Response, by leaving Correct Response out of the arguments of `group_by()`

```{r}
file1 %>% 
  group_by(`Participant Code`) %>% 
  summarise(mean_correct = mean(`Response Correct`)) %>% 
  kable(digits=3)
```

Remove cases where the Correct Response was `NA` and recalculate participant-mean accuracy

```{r}
file1 %>% 
  filter(!is.na(`Correct Response`)) %>% 
  group_by(`Participant Code`) %>% 
  summarise(mean_correct_after_removing_Correct_Response_of_NA = mean(`Response Correct`)) %>% 
  kable(digits=3)
```

### File 2 Car Test

This is a plain text file so `read_csv` isn't the right tool. 

Since we don't know the structure of the file, try `read_lines()`

```{r}
(read_lines(files_list[2]))
```

* `\t` indicates "tab", i.e., the file is tab-delimited. 
* the first 9 rows aren't part of the data.
* there isn't a header row (so the first row of the rectangle would be used as column names if we don't take action)

We use that info to try and read in the most "rectangular" version of the data.

```{r, message=F, warning=F}
file2 = read_delim(
  files_list[2], 
  delim="\t", 
  skip=9, 
  col_names = FALSE)
#file2
```

```{r}
file2 %>% kable()
```

We can see that some rows are per-trial info, and others constitute self-contained summaries that aren't part of the by-trial information.

One way to identify trials that **are** part of the trial-by-trial information is that they all start with "t"

```{r}
trial_level_data = file2 %>% 
  filter(str_detect(X1, '^t'))

trial_level_data %>% kable()
```

Correspondingly, we can identify rows that **are not** part of the trial-by-trial information by negating the above - look for the exclamation mark below.

```{r}
non_trial_data = file2 %>% 
  filter(!str_detect(X1, '^t'))

non_trial_data %>% kable()
```

Under "---END OF TEST--" we have the summary statistics pre-computed -- if we don't want to focus on the trial level information, we could just extract this summary.

```{r}
summary_stats = file2 %>% 
  filter(!str_detect(X1, '^t')) %>% 
  filter(str_detect(X3, 'out of'))

summary_stats %>% kable()
```

Let's discard columns that only contain NA

```{r}
summary_stats = summary_stats %>% 
  select_if(~!all(is.na(.)))

summary_stats %>% kable()
```

Let's rename columns and remove redundant columns

```{r}
names(summary_stats) = c("condition", "n_correct", "out_of", "max_possible_correct")
summary_stats = summary_stats %>% select(-out_of)

summary_stats %>% kable()
```

Now we can calculate the proportion correct.

However be careful that you don't try to calcuate over strings as if they were numbers because this will produce errors. Numbers imported from text files, and numbers imported from spreadsheet columns that contain a mixture of strings and numbers, will be represented as strings themselves until you explictly convert them.

Let's first see that R treats the numbers as strings -- look for `<chr>` below, which is short for *character*, another word for *string*. You'll also see `\r` which is a Windows symbol for 'end-of-line'

```{r}
summary_stats
```

So the following attempt to calculate using those strings that merely look like numbers, but which are words as far as R is concerned, will produce the error message given beneath, which contains the clue `non-numeric information`.

```{r}
#| error: true

summary_stats_with_calculations_producing_error <-
  summary_stats %>% 
    mutate(
      proportion_correct = n_correct / max_possible_correct,
      percent_correct = 100 * proportion_correct)
```

It's not the code that's wrong, it's R's representation of the 'numbers' as strings.

So we fix this, not by typing different code for the calculations, but by telling R to treat the strings as numbers, using `as.numeric()` which *coerces* strings to numbers.

```{r, echo=F}
# grab a copy of bad types to print later
ss = summary_stats
```


```{r}
summary_stats = summary_stats %>% 
  mutate(
    n_correct = as.numeric(n_correct),
    max_possible_correct = as.numeric(max_possible_correct))
```

This is **before** coercion

```{r, echo=F}
ss
```

and this is **after** coercion

```{r, echo=F}
summary_stats
```

See that after coercion the numbers columns have type `<dbl>`, short for *double-precision number*

Notice also that now we have coerced the strings to numbers, the Windows end-of-line symbol `\r` (which stand for *return*, as in the *Enter*, or *Return*,  key on the keyboard that you strike when you want a new line in a text document, a term inherited from type-writers where you *returned* the carriage to the beginning of the next line) has been stripped away.

Now we run the same code that produced an error before -- but which now produces the expected result.

```{r}
summary_stats_with_calculations_producing_correct_result <-
  summary_stats %>% 
    mutate(
      proportion_correct = n_correct / max_possible_correct,
      percent_correct = 100 * proportion_correct)
```

```{r, echo=F}
summary_stats_with_calculations_producing_correct_result %>% kable(digits=c(0,0,0,3,1))
```


```{r, echo=F}
summary_stats_with_calculations_producing_correct_result$condition <-
  summary_stats_with_calculations_producing_correct_result$condition %>% 
  str_remove_all(":") %>% 
  str_remove_all("  ") %>% 
  str_remove_all(" $")
```

Notice that the row for `Total` might not be doing what you think.

The grand mean percent_correct giving equal weight to each condition, i.e., simply adding the scores and dividing by the number of scores, is: 

```{r}
summary_stats_with_calculations_producing_correct_result %>% 
  filter(!condition=="Total") %>% 
  summarise(grand_mean_percent_correct = mean(percent_correct)) %>% 
  pull()
```

The total correct given in the table is extracted from the table like this:

```{r}
summary_stats_with_calculations_producing_correct_result %>% 
  select(condition, percent_correct) %>% 
  filter(condition=="Total") %>% 
  pull()
```

The explanation of the difference is that summarising over condition means gives equal weight to each condition, whereas summarising over trials gives a weight to each condition proportional to the number of trials in the condition -- if the conditions have different numbers of trials, the two ways of calculating grand means will yield different results. 


### File 3 Cambridge Face Memory Test

```{r}
readLines(files_list[3])
```

### File 4 3-back task

```{r}
files_list[4]
```

```{r}
readLines(files_list[4])
```

```{r}
read_delim(files_list[4], delim='\t', show_col_types = F)
```

```{r}
read_delim(files_list[4], delim='\t', show_col_types = F) %>% 
  relocate(expected_button, RESPONSE_MOUSE, .after=trial_number) %>% 
  kable()
```

```{r}
file4 = read_delim(files_list[4], delim='\t', show_col_types = F) 
```

```{r}
summary(file4)
```

```{r}
file4 <-
  read_delim(files_list[4], delim='\t', show_col_types = F)  %>% 
  mutate(
    cb_trial =as_factor(cb_trial),
    image_name = as_factor(image_name),
    prac_or_not = as_factor(prac_or_not),
    number = factor(number, levels=seq_along(number)),
    letcase = as_factor(letcase),
    loctyp = as_factor(loctyp),
    sameord = as_factor(sameord)
  )

summary(file4)
```

Remove practice

```{r}
file4 = file4 %>% filter(prac_or_not == "EXP")
summary(file4)
```

```{r}
file4 %>% kable()
```

Before doing any aggregation, calculate trial-level accuracy given the columns coding for the correct response (`expected_button`) and actual response (`RESPONSE_MOUSE`)

From the summary it's not clear what the possible values of the response are, so let's list them

```{r}
file4$expected_button %>% unique() %>% sort()
```

... and the actual responses

```{r}
file4$RESPONSE_MOUSE %>% unique() %>% sort()
```

1. Make a column evaluating accuracy, and move the column near to the start of the data so we don't have to scroll to see it. 

2. We can remove the correct response (`expected_button`) and actual response (`RESPONSE_MOUSE`) in the same step since they are now redundant, as is the column telling us that the trial is experimental rather than practice (note the use of exclamation for negation). 

3. We also don't care about the image name extension (`.jpg`) since it is uninformative, but we want to retain the base name, e.g., if we have `gu2.jpg`, `gu2` contains all the relevant information.

```{r}
file4 <- file4 %>% 
  mutate(accuracy = as.numeric(RESPONSE_MOUSE == expected_button)) %>% 
  relocate(accuracy, .after = trial_number) %>% 
  select(-c(expected_button, RESPONSE_MOUSE, prac_or_not)) %>% 
  mutate(image_name = str_remove(image_name, ".jpg"))

file4 %>% kable()
```

I don't know exactly what the variables are here so let's make some assumptions.

Assume we want mean accuracy for each level of `sameord`, (`{r} (unique(file4$sameord))`), separately for each level of `letcase`, collapsing over trial number and image name and number, and `loctyp`.

Also, when calculating averages using code, it's sometimes helpful to see the group size (how many things we averaged over).

```{r, message=F}
file4s = file4 %>% 
  group_by(sameord, letcase) %>% 
  summarise(
    mean_acc = mean(accuracy),
    mean_acc_percent = 100* mean_acc,
    n_trials_contributing_to_the_mean = n()
    )
```

```{r}
file4s %>% kable(digits = c(0,0,3,1,0))
```

If we plot the results, we should plot the trial-level data if we want a visual representation of the variability in the group.

```{r}
ggplot(data = file4, aes(y=accuracy, x=sameord, color=sameord))+
  stat_summary(fun.data=mean_cl_normal)
```

Assuming that `sameord` of `0` is not part of the data that we actually want, we can remove it inside the call to `ggplot()`

```{r}
ggplot(data = file4 %>% filter(sameord != "0"), aes(y=accuracy, x=sameord, color=sameord))+
  stat_summary(fun.data=mean_cl_normal)
```


## Natalie method 2: With all files

* Cambridge Face Memory Test long form, 
* The Cambridge car test, 
* a 3 back task (RESULTS_FILE) 
* models memory test (23255_P01). **MMT**

### Wrangling

Get subject names for models memory test

```{r}
subjectsmmt = tools::file_path_sans_ext(list.files("data_supplied/natalie/MMT_results/")) %>% as_tibble_col()
```

Get subject names for all other tests

```{r}
subjects3tests = list.files("data_supplied/natalie/Lab results/") %>% as_tibble_col()
```

There are different amounts of subjects and they have different folder names. It's usually better to arrive at consistent file-name structures before going into R.

```{r}
nrow(subjectsmmt)
```

```{r}
nrow(subjects3tests)
```

However the first 65 folders have consistent naming schemes, so let's use those.

```{r}
subjectsmmt = subjectsmmt[1:65,]
subjects3tests = subjects3tests[1:65,]
```

Check that they have the same names

```{r}
names(subjectsmmt) == names(subjects3tests)
```

### Data Structure

Let's use a list with tasks as the elements contained in tibbles.

```{r}
tasks = c("Memory", "Car", "Face", "Face Summary", "Nback", "Nback Summary")
subjects = subjectsmmt$value
alld = list()
for (subject in subjects){
  alld[[subject]] = list()
  for (task in tasks){
    alld[[subject]][[task]]=tibble()
  }
}
```

We can refer using numeric or named indices

```{r, eval=F}
alld[['23255_P01']][['Memory']]
alld[[65]][[2]]
```

```{r, eval=F}
head(alld)
```

### Loop

Now we can set about bringing in the different results files and assigning them to the proper participant.

#### Models Memory Task

```{r}
mmt_folders = "data_supplied/natalie/MMT_results" 
mmt_files = list.files(mmt_folders, full.names = TRUE)

for (mmt in mmt_files){
  if(tools::file_path_sans_ext(basename(mmt)) %in% subjects3tests$value){
    subject = tools::file_path_sans_ext(basename(mmt))
    task = "Models Memory Task"
    fin=read_csv(mmt, show_col_types = F) %>% 
      mutate(subject=subject) %>% 
      relocate(subject) %>% 
      select(-`Participant Code`) %>%
      mutate(task = task) %>% relocate(task, .before = subject) %>% 
      rename(image_name = `Image Name`, correct_response = `Correct Response`, actual_response = `Participant Response`, accuracy = `Response Correct`)
    
    alld[[subject]][['Memory']] = fin
  }
}
```

#### Car Test

```{r, warning=F}
car_folders = list.files("data_supplied/natalie/Lab results", full.names = T)


for (car_folder in car_folders){
  if(basename(car_folder) %in% subjects3tests$value){
    subject = basename(car_folder)
    task = "Car Test"
    car_file = list.files(car_folder, pattern = "^Car", full.names = T)
    fin = suppressWarnings(read_delim(
      show_col_types = F,
      car_file,
      delim="\t",
      skip=9,
      col_names = FALSE) %>%
      filter(str_detect(X1, '^t')))
    names(fin) = c("event", "picture", "RT", "response", "target", "correct", "ignore")
    fin = fin %>% 
      select(-ignore) %>% 
      mutate(subject=subject) %>% relocate(subject) %>% 
      mutate(task = task) %>% relocate(task, .before = subject)
    
    alld[[subject]][['Car']] = fin
  }
}
```


#### Cambridge Face Memory Test

```{r, warning=F}
face_folders = list.files("data_supplied/natalie/Lab results", full.names = T)

for (face_folder in face_folders){
  if(basename(face_folder) %in% subjects3tests$value){
    subject = basename(face_folder)
    task = "Cambrisge Face Memory Task"
    face_file = list.files(face_folder, pattern = "^CMTF", full.names = T)
    
    fin = suppressWarnings(read_delim(face_file, delim='\t', skip=5, show_col_types = F)) %>% 
      separate_wider_delim(correct, delim='\t', names=c("correct", "phase")) %>% 
      mutate(phase=ifelse(phase=="", "experimental", phase)) %>% 
      mutate(subject = subject) %>% relocate(subject) %>% 
      mutate(task = task) %>% relocate(task, .before = subject)
    
    extracted_summary = suppressWarnings(fin %>% 
      filter(is.na(target)) %>% 
      mutate(response=parse_number(response),
             RT=parse_number(RT),
             max_possible=coalesce(response, RT),
             score_component_of_event = as.numeric(event),
             score_component_of_picture = as.numeric(picture),
             score=coalesce(score_component_of_event, score_component_of_picture)) %>% 
      relocate(score, .before=max_possible) %>% 
      select(c(subject, event, score, max_possible)) %>% 
      mutate(percent_score = 100*(score / max_possible)) %>% 
      mutate(event=str_remove_all(event, "-")) %>% 
      slice_tail(n=6) %>% slice_head(n=5) %>% 
      mutate(event = str_remove(event, ":"),
             event = str_squish(event))) %>% 
      mutate(task = task) %>% relocate(task, .before = subject) 
    
    alld[[subject]][['Face']] = fin
    alld[[subject]][['Face Summary']] = extracted_summary
  
    }
}
```

#### Nback

```{r, warning=F}
nback_folders = list.files("data_supplied/natalie/Lab results", full.names = T)

for (nback_folder in nback_folders){
  if(basename(nback_folder) %in% subjects3tests$value){
    subject = basename(nback_folder)
    task = "Nback"
    nback_file = list.files(nback_folder, 
                            pattern = "^RESULTS", 
                            full.names = T)
    
    fin = suppressWarnings(read_delim(face_file, delim='\t', skip=5, show_col_types = F) %>% 
      separate_wider_delim(correct, delim='\t', names=c("correct", "phase"))  %>% 
      mutate(phase=ifelse(phase=="", "experimental", phase)) %>%
      mutate(subject = subject) %>% relocate(subject)) %>% 
      mutate(task = task) %>% relocate(task, .before = subject)
     
    extracted_summary = suppressWarnings(fin %>%
      filter(is.na(target)) %>%
      mutate(response=parse_number(response),
             RT=parse_number(RT),
             max_possible=coalesce(response, RT),
             score_component_of_event = as.numeric(event),
             score_component_of_picture = as.numeric(picture),
             score=coalesce(score_component_of_event, score_component_of_picture)) %>%
      relocate(score, .before=max_possible) %>%
      select(c(subject, event, score, max_possible)) %>%
      mutate(percent_score = 100*(score / max_possible)) %>%
      mutate(event=str_remove_all(event, "-")) %>%
      slice_tail(n=6) %>% slice_head(n=5) %>%
      mutate(event = str_remove(event, ":"),
             event = str_squish(event))) %>% 
      mutate(task = task) %>% relocate(task, .before = subject)

    alld[[subject]][['Nback']] = fin
    alld[[subject]][['Nback Summary']] = extracted_summary

    }
}
```

#### Putting it al together

This seeems to make a list-column

```{r, message=FALSE}
allsubs=tibble()
j=0
for(i in subjects3tests$value){
  j=j+1
  mem   = nest(alld[[i]][['Memory']], .by=subject, .key="Mem")
  car   = nest(alld[[i]][['Car']], .by=subject, .key="Car")
  face  = nest(alld[[i]][['Face']], .by=subject, .key="Face")
  nback = nest(alld[[i]][['Nback']], .by=subject, .key="Nback")
  alltasks = left_join(mem, car)
  alltasks = left_join(alltasks, face)
  alltasks = left_join(alltasks, nback)
  allsubs[j,"subject"] = alltasks$subject

  allsubs[j,"car"] = list(alltasks$Car)
  allsubs[j,"mem"] = list(alltasks$Mem)
  allsubs[j,"face"] = list(alltasks$Face)
  allsubs[j,"Nback"] = list(alltasks$Nback)
}

```

